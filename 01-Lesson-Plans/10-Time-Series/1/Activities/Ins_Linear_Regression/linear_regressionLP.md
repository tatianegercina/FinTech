### Instructor Do: Introduction to Linear Regression (0:10)

* Open the first slide [slideshow](tbd) and explain the linear equation:

  ```
  y = mx + b
  ```
  
  ![Image](image)
  
  * This equation describes, or models, the relationship between variables x and y.

  * As x increases, y increases.

  * How fast y increases in relation to x is called the slope.

  * Slope is represented by the letter `m` in the equation.

  * The value of `y` when `x` is 0 is called the y-intercept. It is represented by the letter `b`.

* Open the next [slide](tbd) and ask whether, on visual inspection, a trend exists:

  ![image](scatter plot)
  
  * `y` increases as `x` increases.
  
* Explain that a line that best fits the trend can be drawn:

  ![image](best fit line)
  
  * This line is called the best fit line, and computing it is called linear regression.

  * The equation is simple but tedious, and is best solved by a computer. 

  * [link to equation](tbd)

* Explain that, in other words, linear regresson identifies the line that best predicts `y` based on the value of `x`.  

* Explain the concept of residuals.

  * Even a best fit line that captures the data well is almost never perfect. 

  * A residual is the difference between the **predicted** value of `y` and its **actual** value.

  * Linear regression seeks to minimize the **square** value of residuals.

* Summarize the key points of linear regression:

  * It models data with a linear trend. It is not useful when the data does not follow a linear trend, e.g. curved trends.

  * Based on the X values, it predicts Y values.


### Instructor Do: Linear Regression in Scikit-Learn (0:10)

* Now open the [notebook](tbd) and go over running linear regression in Python with scikit-learn.

### Student Do: Linear Regression (0:15)

* **Files:**

* etc


### Instructor Do: Activity Review (0:05)


### Instructor Do: Time Series Linear Regression (0:10)


### Student Do: Time Series Linear Regression (0:15)


### Instructor Do: Activity Review (0:05)
