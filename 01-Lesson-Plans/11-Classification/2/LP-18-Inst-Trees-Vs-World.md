### 18. Instructor Do: The Trees Versus the World (10 min)

In this activity, instructor will conduct a facilitated discussion in the class where students will be able to compare the strengths and weaknesses of decision trees, random forests, and classical classifiers (Logistic Regression, SVM, KNN).

Open the lesson slides, go to _The Trees Vs. The World_ section and start the discussion by asking the class the following question:

* Why do you think is worth to learn about classification algorithms?

Ask a couple of students to answer the question, provide your feedback by continuing with the first slide of the section and mentioning that classification algorithms are a matter worth of study since classification is a multidisciplinary challenge.

* **Finance and Banking:** Fraud detection, money laundry, credit risk assessment.

* **Retail and Marketing:** customized products offers, products recommendation, direct marketing optimization.

* **Politics:** Vote intention, party affinity.

* **Health:** Trials tests, ills diagnosis.

* **Security:** Intruders detection, predictive maintenance.

* **Education:** Programs affinity, customized curricula, desertion prevention.

Follow the discussion by asking students the next question:

* Are tree based algorithms the strongest for classification?

Ask for one volunteer to answer the question, after listening to student's answer, comment to students some the the strengths of tree based algorithms:

* Are easy to represent, making a complex model much easier to interpret.

* Can be used for any type of data: Numerical (e.g. loan’s amount) or categorical (e.g. bank’s name that issues a
loan).
* Require little data preparation.

* Can handle data that are not normally distributed.

* Can avoid overfitting.

Continue the presentation by showing to students, some of the cases when classical classifiers perform better than tree based algorithms:

* Generally speaking, classical classifiers may be faster.

* Logistic regression may outperform Decision trees or random forests  having a large number of features with with low noise.

* SVM also support linear and non-linear models.

* SVM handles outliers better.

* KNN naturally supports incremental learning (data streams).

Close the discussion by asking this final question:

* Which algorithm should I use for classification?

Ask for one or two students to voluntary answer the question, and conclude by highlighting the following:

* There is no a definitive answer to this question, the best answers is _it depends_.

* The best algorithm for a classification problem will be determined by different factors such as:

  * Type of data (categorical, numerical, a combination of both).

  * Target classes distribution (balanced or imbalanced).

  * Number of features (input variables).

  * Data normality.

  * Data linearity.

  * Dataset size (number of records or samples)

Congratulate students on learning about a new family of machine learning algorithms, answer any questions before ending the class.
